\documentclass[LI,VKR]{HSEUniversity}
% Возможные опции: KR или VKR; LI

\title{Оценка применимости метода детектирования семантических изменений слов нейросетевой языковой моделью на основе генерируемых определений}
\author{Максим Дмитриевич Татаринов}
\supervisor{доцент факультета информатики, математики и компьютерных наук ВШЭ}{А. В.~Демидовский}
\reviewer{TBD}{П.П.~Петров}

\Year{2023}
\City{Нижний Новгород}

% \Abstract{
% 	Будущая аннотация.
% }

\addbibresource{library.bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ТЕКСТ РАБОТЫ %%%%%%%%%%%%%%%
\begin{document}

% Обязательные элементы оформления: заголовочный слайд, аннотация, оглавление
\maketitle

\chapter*{Введение}


\textbf{Целью} настоящей работы является оценка применимости метода детектирования семантических
изменений слов нейросетевой языковой моделью на основе генерируемых определений.

Из поставленной цели были сформулированы следующие \textbf{задачи}:
\begin{enumerate}
    \item  Провести анализ существующей литературы и решений по задаче детектирования семантических
    изменений на основе генерируемых определений.
    \item  Собрать тезаурус русского языка в качестве материала для обучения модели, а также
    диахронический корпус текстов на основе НКРЯ.
    \item  Обучить языковую модель на данных тезауруса для того, чтобы генерировать определения.
    \item  Провести анализ метрик и качества обученной языковой модели и сравнить их с
    существующими решениями.
    \item  Создать алгоритм автоматического определения семантических сдвигов на основе их
    векторного представления.
    \item  Провести комплексный лингвистический анализ результатов работы компьютерной программы.
    \item  Разработать прототип системы, позволяющей проводить анализ семантических изменений
    сторонним исследователям, используя разработанный в настоящей работе алгоритм.
\end{enumerate}

\textbf{Объектом} исследования является метод детектирования семантических изменений слов.

\textbf{Предметом} исследования является применимость метода детектирования семантических изменений
слов с использованием нейросетевой языковой модели на основе генерируемых определений.

Для решения поставленных задач были использованы следующие \textbf{методы}:
\begin{enumerate}
    \item  Метод анализа и синтеза для создания теоретической базы для данного исследования на основе
литературы.
    \item  Компьютерный метод для написания алгоритмов программы и обучения модели.
    \item  Методы обработки естественного языка для предобработки текстов.
    \item  Методы машинного обучения для алгоритма автоматического определения семантических сдвигов на
основе их векторного представления.
    \item  Метод комплексного лингвистического анализа результатов работы алгоритма.
\end{enumerate}

\textbf{Актуальность} настоящей работы состоит в том, что, во-первых, вопрос анализа семантических
изменений в русском языке на основе автоматически сгенерированных определений недостаточно
изучен. Так, в настоящее время представление слов с помощью сгенерированных определений
является перспективной темой для поиска семантических изменений, с еще небольшим
количеством статей на данную тему на английском языке и отсутствием таких для русского.
Во-вторых, традиционные методы поиска семантических изменений недостаточно информативны
для основных потенциальных пользователей, таких как лексикографы или историки языка~\cite{DefinitionGenerationMainArticle}.
Им хотелось бы получать описания старых и новых значений слов в пригодной для чтения форме, возможно,
даже с дополнительными пояснениями.

\textbf{Новизна} настоящей работы состоит в создании компьютерной программы, позволяющей автоматически
определять семантические изменения, с использованием автоматически сгенерированных определений,
а также применением этого метода на русском языке.

\textbf{Практическая значимость} данной работы заключается в том, что результаты работы программы можно
применять для определения степени семантического сдвига лексем, с наличием визуализаций и
определений для каждого выявленного значения, что может быть использовано в лексикологии,
где необходимы актуальные данные построения новых словарей.

В качестве \textbf{материала исследования} используется диахронический корпус НКРЯ, охватывающий три
периода (1700—1916, 1918—1991 и 1992—2016 годы) и имеющий в совокупности 250 миллионов
словоупотреблений. Данный корпус выбран, поскольку золотой датасет слов с изменившимся
и неизменившимся значением, использующийся для оценки модели, основан на данном корпусе.
Корпус был получен по запросу к авторам НКРЯ.


\chapter{Имплементация автоматического выявления семантических изменений}

\section{Обучение языковой модели на данных тезауруса}

В качестве модели была выбрана FRED-T5-1.7B, являющаяся одной из новейших языковых моделей,
выпущенных SberDevices и обученных с нуля на материале русского языка~\cite{FRED-T5}.
Для выбора модели мы использовали бенчмарк для оценки продвинутого понимания русского языка
\("\)RussianSuperGLUE\("\)~\cite{RussianSuperGLUE}. В бенчмарке присутствуют шесть групп задач, охватывая
общую диагностику языковых моделей и различные лингвистические задачи: понимание здравого смысла, логическое
следование в естественном языке, рассуждения, машинное чтение и знания о мире.
FRED-T5-1.7B занимает самое высокое место в лидерборде данного бенчмарка, со значением 0.762,
уступая лишь результатам выполнения данных заданий людьми со значением 0.811,
что свидетельствует о ее способности к выдающемуся языковому пониманию и анализу.
Таким образом, FRED-T5-1.7B представляется нам наиболее подходящей языковой моделью
для задачи генерации определений.

В качестве материала, используемого для обучения модели, выступила русская версия Викисловаря.
Материал получен с помощью самостоятельно написанного скрипта на языке Python, позволяющего
извлечь данные из выгрузки Викисловаря в формат JSONL, где в каждом вхождении присутствовали
идентификатор статьи, лексема, про которую написана данная статья, а также определения
с примерами использования.

FRED-T5-1.7B была дообучена на полученном из Викисловаря материале, где на вход модель
принимает лексему и контекст, в которой она употреблялась, а на выход ожидается сгенерированное
определение.

Для оценки качества обучения модели используются метрики BLEU и ROUGE-L,
которые оценивают формальную схожесть текста: BLEU оценивает точность совпадений n-грамм
в сгенерированном тексте по сравнению с эталонным текстом~\cite{BLUE}, а ROUGE-L измеряет схожесть между
сгенерированным текстом и эталонным текстом на основе наибольшей общей последовательности слов~\cite{ROUGE}.
Также использовалась метрика BERT-F1, которая учитывает семантику сравниваемых текстов, так как
использует модель BERT, представитель семейства моделей Transformer, обученные
на больших объемах текста и имеющие глубокое понимание семантики~\cite{BERTScore}.
Использование нескольких метрик позволяет получить более полную картину качества модели,
поскольку каждая из них оценивает разные аспекты сгенерированного текста.
Как традиционные BLEU и ROUGE-L, так и более современный BERT-F1 активно используются в
задачах обработки естественного языка, в том числе в задачах генерации текста.
В данной работе использовались версии этих инструментов, взятые из библиотеки evaluate~\cite{Evaluate}.
Так, в обзорной статье по моделированию определений утверждается, что на момент выпуска статьи BLUE
использовался в 9 научных публикациях, ROUGE-L и BERTScore – в 3~\cite{DefinitionModelingReviewAndDatasetAnalysis}.
Кроме того, данные метрики используются и в более новых работах.
Так, в настоящей статье результаты данных метрик будут сравниваться с таковыми из статьи
Giulianelli M. et al., где сообщаются результаты трёх вышеперечисленных метрик при обучении модели
Т5 для задаче генерации определений на английском языке~\cite{DefinitionGenerationMainArticle}.

\printbibliography

\end{document}
